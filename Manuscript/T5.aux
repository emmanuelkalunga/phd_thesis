\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{jost_riemannian_2011}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Riemannian Geometry for Brain-Computer Interfaces}{79}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:riem-geom-bci}{{5}{79}{Riemannian Geometry for Brain-Computer Interfaces}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Riemannian Manifold of Symmetric Positive-Definite Matrices}{79}{section.5.1}}
\newlabel{sec:riemann-manifold}{{5.1}{79}{Riemannian Manifold of Symmetric Positive-Definite Matrices}{section.5.1}{}}
\newlabel{eq:rm}{{5.1}{79}{Riemannian Manifold of Symmetric Positive-Definite Matrices}{section.5.1}{}}
\newlabel{eq:sy}{{5.1}{80}{Riemannian Manifold of Symmetric Positive-Definite Matrices}{section.5.1}{}}
\newlabel{eq:exp_r}{{5.1.1}{80}{Riemannian Manifold of Symmetric Positive-Definite Matrices}{equation.5.1.1}{}}
\newlabel{eq:log_r}{{5.1.2}{80}{Riemannian Manifold of Symmetric Positive-Definite Matrices}{equation.5.1.2}{}}
\newlabel{eq:sqm}{{5.1}{80}{Riemannian Manifold of Symmetric Positive-Definite Matrices}{equation.5.1.2}{}}
\newlabel{eq:tan_geo}{{5.1.3}{80}{Riemannian Manifold of Symmetric Positive-Definite Matrices}{equation.5.1.3}{}}
\citation{fukunaga_introduction_1990}
\citation{fukunaga_introduction_1990}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Covariance Matrix Estimation}{81}{section.5.2}}
\newlabel{sec:covmat-estimation}{{5.2}{81}{Covariance Matrix Estimation}{section.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Sample Covariance Matrix Estimator}{81}{subsection.5.2.1}}
\citation{ledoit_well-conditioned_2004}
\citation{blankertz_single-trial_2011}
\citation{schafer_shrinkage_2005}
\citation{pascal_theoretical_2005}
\newlabel{eq:nscme}{{5.2.2}{82}{Sample Covariance Matrix Estimator}{equation.5.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Shrinkage Covariance Matrix Estimators}{82}{subsection.5.2.2}}
\newlabel{eq:shrink}{{5.2.3}{82}{Shrinkage Covariance Matrix Estimators}{equation.5.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Fixed-Point Covariance Matrix Estimator}{82}{subsection.5.2.3}}
\newlabel{eq:max_lik}{{5.2.4}{82}{Fixed-Point Covariance Matrix Estimator}{equation.5.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Classification of SSVEP Covariance Matrices}{83}{section.5.3}}
\newlabel{sec:classification-covmat}{{5.3}{83}{Classification of SSVEP Covariance Matrices}{section.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Machine Learning Approach for Classification}{83}{subsection.5.3.1}}
\newlabel{subsec:fund_class}{{5.3.1}{83}{Machine Learning Approach for Classification}{subsection.5.3.1}{}}
\newlabel{eq:mean_eucl1}{{5.3.1}{83}{Machine Learning Approach for Classification}{equation.5.3.1}{}}
\newlabel{eq:mean_eucl2}{{5.3.2}{83}{Machine Learning Approach for Classification}{equation.5.3.2}{}}
\citation{scholkopf_learning_2001}
\newlabel{eq:classif1}{{5.3.3}{84}{Machine Learning Approach for Classification}{equation.5.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Means of Covariance Matrices}{84}{subsection.5.3.2}}
\newlabel{subsec:mean}{{5.3.2}{84}{Means of Covariance Matrices}{subsection.5.3.2}{}}
\citation{karcher_riemannian_2014}
\citation{ando2004geometric,lim_matrix_2012}
\citation{lim_matrix_2012}
\citation{pennec_riemannian_2006}
\citation{arsigny_geometric_2007}
\citation{VIL08}
\citation{nielsen_sided_2009}
\citation{sra_positive_2016}
\citation{nielsen_clustering_2014}
\citation{chebbi_means_2012}
\newlabel{eq:mean}{{5.3.5}{85}{Means of Covariance Matrices}{equation.5.3.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Distances and Divergences}{85}{section*.21}}
\citation{lim_matrix_2012}
\citation{arsigny_geometric_2007}
\citation{pennec_riemannian_2006}
\@writefile{toc}{\contentsline {subsubsection}{Euclidean Distance}{86}{section*.22}}
\newlabel{sec:eucl-distance}{{5.3.2}{86}{Euclidean Distance}{section*.22}{}}
\newlabel{eq:dist_eucl}{{5.3.6}{86}{Euclidean Distance}{equation.5.3.6}{}}
\newlabel{eq:mean_arithmetic}{{5.3.7}{86}{Euclidean Distance}{equation.5.3.7}{}}
\newlabel{eq:mean_power}{{5.3.8}{86}{Euclidean Distance}{equation.5.3.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{Affine-Invariant Riemannian Distance}{86}{section*.23}}
\citation{fletcher_principal_2004}
\newlabel{eq:dist_air}{{5.3.9}{87}{Affine-Invariant Riemannian Distance}{equation.5.3.9}{}}
\newlabel{mean_air}{{5.3.10}{87}{Affine-Invariant Riemannian Distance}{equation.5.3.10}{}}
\newlabel{eq:invar_congr}{{5.3.11}{87}{Affine-Invariant Riemannian Distance}{equation.5.3.11}{}}
\citation{arsigny_geometric_2007}
\citation{arsigny_geometric_2007}
\citation{arsigny_geometric_2007}
\newlabel{eq:invar_invers}{{5.3.12}{88}{Affine-Invariant Riemannian Distance}{equation.5.3.12}{}}
\newlabel{eq:invar_invers2}{{5.3.13}{88}{Affine-Invariant Riemannian Distance}{equation.5.3.13}{}}
\newlabel{eq:invar_mult}{{5.3.14}{88}{Affine-Invariant Riemannian Distance}{equation.5.3.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{Log-Euclidean Distance}{88}{section*.24}}
\newlabel{eq:dist_LE}{{5.3.15}{88}{Log-Euclidean Distance}{equation.5.3.15}{}}
\newlabel{eq:mean_LE}{{5.3.16}{88}{Log-Euclidean Distance}{equation.5.3.16}{}}
\citation{VIL08}
\citation{VIL08}
\citation{barbaresco_geometric_2011}
\citation{amari_information_2010}
\citation{bregman_relaxation_1967}
\@writefile{toc}{\contentsline {subsubsection}{Wasserstein Distance}{89}{section*.25}}
\newlabel{eq:opttrans}{{5.3.17}{89}{Wasserstein Distance}{equation.5.3.17}{}}
\newlabel{eq:wasser}{{5.3.18}{89}{Wasserstein Distance}{equation.5.3.18}{}}
\newlabel{eq:dist_wass}{{5.3.19}{89}{Wasserstein Distance}{equation.5.3.19}{}}
\newlabel{eq:dist_wass_2}{{5.3.20}{89}{Wasserstein Distance}{equation.5.3.20}{}}
\citation{bregman_relaxation_1967}
\@writefile{toc}{\contentsline {subsubsection}{Bregman Divergences}{90}{section*.26}}
\newlabel{sec:bregman-divergence}{{5.3.2}{90}{Bregman Divergences}{section*.26}{}}
\newlabel{eq:bregman-div}{{5.3.21}{90}{Bregman Divergences}{equation.5.3.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Geometry of the Bregman divergence with the seed function $f(z)=\frac  {1}{2}z^\intercal z$. $h(z)$ is a hyperplane tangent to $f(z)$ at $y$. While it accurately represents $f(y)$, it underestimates $f(x)$. The Bregman divergence measures how much the representation of $f(x)$ on $h(z)$ \emph  {diverges} from $f(x)$ (in green).}}{90}{figure.5.1}}
\newlabel{fig:bregman-projection}{{5.1}{90}{Geometry of the Bregman divergence with the seed function $f(z)=\frac {1}{2}z^\intercal z$. $h(z)$ is a hyperplane tangent to $f(z)$ at $y$. While it accurately represents $f(y)$, it underestimates $f(x)$. The Bregman divergence measures how much the representation of $f(x)$ on $h(z)$ \emph {diverges} from $f(x)$ (in green)}{figure.5.1}{}}
\citation{nielsen_sided_2009}
\citation{dhillon_matrix_2007}
\citation{nielsen_sided_2009}
\newlabel{eq:div-eucl}{{5.3.23}{91}{Bregman Divergences}{equation.5.3.23}{}}
\newlabel{eq:kl}{{5.3.24}{91}{Bregman Divergences}{equation.5.3.24}{}}
\citation{sra_positive_2016}
\citation{sra_positive_2016}
\citation{sra_positive_2016}
\citation{nielsen_clustering_2014}
\citation{chebbi_means_2012}
\newlabel{eq:normal-distr}{{5.3.25}{92}{Bregman Divergences}{equation.5.3.25}{}}
\newlabel{eq:div-kl-gen}{{5.3.26}{92}{Bregman Divergences}{equation.5.3.26}{}}
\newlabel{eq:div-kl-proba}{{5.3.27}{92}{Bregman Divergences}{equation.5.3.27}{}}
\newlabel{eq:div-kl}{{5.3.28}{92}{Bregman Divergences}{equation.5.3.28}{}}
\newlabel{eq:div-js}{{5.3.29}{92}{Bregman Divergences}{equation.5.3.29}{}}
\newlabel{eq:div-s}{{5.3.30}{92}{Bregman Divergences}{equation.5.3.30}{}}
\citation{chebbi_means_2012,sra_positive_2016}
\citation{lim_matrix_2012}
\citation{arsigny_geometric_2007}
\citation{fletcher_principal_2004}
\citation{moakher_differential_2005,fletcher_principal_2004}
\citation{chebbi_means_2012,kang_composite_2009}
\citation{cherian_efficient_2011}
\citation{sra_positive_2016,cherian_efficient_2011}
\citation{chebbi_means_2012}
\citation{chebbi_means_2012}
\citation{chebbi_means_2012}
\citation{nielsen_matrix_2012,chebbi_means_2012}
\citation{agueh_barycenters_2011}
\citation{agueh_barycenters_2011,barbaresco_geometric_2011}
\citation{barachant_multiclass_2012}
\citation{congedo_new_2013}
\newlabel{eq:div-alpha}{{5.3.31}{93}{Bregman Divergences}{equation.5.3.31}{}}
\newlabel{eq:div-alpha2}{{5.3.32}{93}{Bregman Divergences}{equation.5.3.32}{}}
\newlabel{eq:div-log-det-alpha}{{5.3.33}{93}{Bregman Divergences}{equation.5.3.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Minimum Distance to Mean Classifier for SSVEP}{93}{subsection.5.3.3}}
\newlabel{subsec:mdm}{{5.3.3}{93}{Minimum Distance to Mean Classifier for SSVEP}{subsection.5.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Distances, divergences and means considered in the experimental study.}}{94}{table.5.1}}
\newlabel{tab:dist}{{5.1}{94}{Distances, divergences and means considered in the experimental study}{table.5.1}{}}
\newlabel{eq:ext_data}{{5.3.34}{94}{Minimum Distance to Mean Classifier for SSVEP}{equation.5.3.34}{}}
\newlabel{eq:ext_data_erp}{{5.3.35}{94}{Minimum Distance to Mean Classifier for SSVEP}{equation.5.3.35}{}}
\citation{barachant_riemannian_2013}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Minimum Distance to Mean Classifier}}{95}{algorithm.1}}
\newlabel{alg:mdm}{{1}{95}{Minimum Distance to Mean Classifier for SSVEP}{algorithm.1}{}}
\newlabel{op:class_center}{{3}{95}{Minimum Distance to Mean Classifier for SSVEP}{algorithm.1}{}}
\newlabel{op:decision}{{5}{95}{Minimum Distance to Mean Classifier for SSVEP}{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Online Classification}{95}{section.5.4}}
\newlabel{sec:online-classification}{{5.4}{95}{Online Classification}{section.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Curve-Based Online Classification}{95}{subsection.5.4.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Offline Estimation of Riemannian Centres of Classes}}{96}{algorithm.2}}
\newlabel{alg:r_mean}{{2}{96}{Minimum Distance to Mean Classifier for SSVEP}{algorithm.2}{}}
\newlabel{op:cov_i}{{1}{96}{Minimum Distance to Mean Classifier for SSVEP}{algorithm.2}{}}
\newlabel{op:class_center}{{3}{96}{Minimum Distance to Mean Classifier for SSVEP}{algorithm.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Curve-based Online Classification}}{96}{algorithm.3}}
\newlabel{alg:online}{{3}{96}{Curve-Based Online Classification}{algorithm.3}{}}
\newlabel{op3:epoch_and_classify}{{3}{96}{Curve-Based Online Classification}{algorithm.3}{}}
\newlabel{op3:test_len}{{4}{96}{Curve-Based Online Classification}{algorithm.3}{}}
\newlabel{op3:get_rho}{{5}{96}{Curve-Based Online Classification}{algorithm.3}{}}
\newlabel{op3:test_rho}{{6}{96}{Curve-Based Online Classification}{algorithm.3}{}}
\newlabel{op3:get_disvec}{{7}{96}{Curve-Based Online Classification}{algorithm.3}{}}
\newlabel{op3:test_disvec}{{8}{96}{Curve-Based Online Classification}{algorithm.3}{}}
\newlabel{op3:valid_class}{{9}{96}{Curve-Based Online Classification}{algorithm.3}{}}
\newlabel{op3:increment_d}{{13}{96}{Curve-Based Online Classification}{algorithm.3}{}}
\citation{verschore_dynamic_2012}
\newlabel{eq:online_epoch}{{5.4.1}{97}{Curve-Based Online Classification}{equation.5.4.1}{}}
\newlabel{eq:occ_prob}{{5.4.2}{97}{Curve-Based Online Classification}{equation.5.4.2}{}}
\newlabel{eq:dist_vec}{{5.4.3}{97}{Curve-Based Online Classification}{equation.5.4.3}{}}
\citation{barachant_riemannian_2013}
\citation{barachant_riemannian_2013}
\citation{congedo2013eeg}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Outliers Removal with Riemannian Potato}{99}{subsection.5.4.2}}
\newlabel{sec:potato}{{5.4.2}{99}{Outliers Removal with Riemannian Potato}{subsection.5.4.2}{}}
\newlabel{eq:potato}{{5.4.4}{99}{Outliers Removal with Riemannian Potato}{equation.5.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Experimental Validation}{100}{section.5.5}}
\newlabel{sec:experimental-validation}{{5.5}{100}{Experimental Validation}{section.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Covariance Estimators Comparison}{100}{subsection.5.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Comparison of covariance estimators in terms of classification accuracy obtained with MDRM with increasing EEG trial length. For each trial length, the average accuracy across all subjects and across all replication is shown. Bars indicate the error of the mean, i.e. standard deviation divided by the square root of $n-1$, $n$ = number of samples.}}{100}{figure.5.2}}
\newlabel{fig:acc_errorbar}{{5.2}{100}{Comparison of covariance estimators in terms of classification accuracy obtained with MDRM with increasing EEG trial length. For each trial length, the average accuracy across all subjects and across all replication is shown. Bars indicate the error of the mean, i.e. standard deviation divided by the square root of $n-1$, $n$ = number of samples}{figure.5.2}{}}
\citation{pencina_evaluating_2008}
\newlabel{fig:eigenvalue_range}{{5.3(a)}{102}{Subfigure 5 5.3(a)}{subfigure.5.3.1}{}}
\newlabel{sub@fig:eigenvalue_range}{{(a)}{102}{Subfigure 5 5.3(a)\relax }{subfigure.5.3.1}{}}
\newlabel{fig:idi}{{5.3(b)}{102}{Subfigure 5 5.3(b)}{subfigure.5.3.2}{}}
\newlabel{sub@fig:idi}{{(b)}{102}{Subfigure 5 5.3(b)\relax }{subfigure.5.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces (a) Covariance matrices condition expressed as the ratio $\mathcal  {C}$ between largest and smallest eigenvalues for the different covariance estimators. The comparison is made for increasing EEG trial length. (b) Integrated discrimination improvement brought to the classification task by various estimators along varying trail length. The indicated IDI values are multiplied by $10^{2}$. $\ensuremath  {\mathaccentV {hat}05E{\Sigma }_{\operatorname  {scm}}}$ is used as a baseline. }}{102}{figure.5.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{102}{figure.5.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{102}{figure.5.3}}
\newlabel{fig:class_idi}{{5.3}{102}{(a) Covariance matrices condition expressed as the ratio $\mathcal {C}$ between largest and smallest eigenvalues for the different covariance estimators. The comparison is made for increasing EEG trial length. (b) Integrated discrimination improvement brought to the classification task by various estimators along varying trail length. The indicated IDI values are multiplied by $10^{2}$. $\cov {scm}$ is used as a baseline}{figure.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Effect of Outliers on Centre Estimation}{103}{subsection.5.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}From Euclidean to Riemannian Centres of Class}{103}{subsection.5.5.3}}
\newlabel{subsec: from-euclid-to-riemann}{{5.5.3}{103}{From Euclidean to Riemannian Centres of Class}{subsection.5.5.3}{}}
\newlabel{fig:tan_plan_s16_a}{{5.4(a)}{104}{Subfigure 5 5.4(a)}{subfigure.5.4.1}{}}
\newlabel{sub@fig:tan_plan_s16_a}{{(a)}{104}{Subfigure 5 5.4(a)\relax }{subfigure.5.4.1}{}}
\newlabel{fig:tan_plan_s16_b}{{5.4(b)}{104}{Subfigure 5 5.4(b)}{subfigure.5.4.2}{}}
\newlabel{sub@fig:tan_plan_s16_b}{{(b)}{104}{Subfigure 5 5.4(b)\relax }{subfigure.5.4.2}{}}
\newlabel{fig:tan_plan_s17_a}{{5.4(c)}{104}{Subfigure 5 5.4(c)}{subfigure.5.4.3}{}}
\newlabel{sub@fig:tan_plan_s17_a}{{(c)}{104}{Subfigure 5 5.4(c)\relax }{subfigure.5.4.3}{}}
\newlabel{fig:tan_plan_s17_b}{{5.4(d)}{104}{Subfigure 5 5.4(d)}{subfigure.5.4.4}{}}
\newlabel{sub@fig:tan_plan_s17_b}{{(d)}{104}{Subfigure 5 5.4(d)\relax }{subfigure.5.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Scatter plot of covariance matrices for all trials mapped on the tangent space. The distance between each trial covariance matrix $\ensuremath  {\Sigma }_{\ensuremath  {i}}$ and its Riemannian mean class $\ensuremath  {\Sigma }_{\ensuremath  {\mu }}^{(\ensuremath  {k})}$ is shown as connection line. The black star represents the Riemannian mean of all trials. Subject with lowest BCI performance, (\ref  {fig:tan_plan_s16_a}) before and (\ref  {fig:tan_plan_s16_b}) after Riemannian potato filtering. Subject with highest BCI performance, (\ref  {fig:tan_plan_s17_a}) before and (\ref  {fig:tan_plan_s17_b}) after Riemannian potato filtering.}}{104}{figure.5.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{104}{figure.5.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{104}{figure.5.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{104}{figure.5.4}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{104}{figure.5.4}}
\newlabel{fig:tan_plan_s16&17}{{5.4}{104}{Scatter plot of covariance matrices for all trials mapped on the tangent space. The distance between each trial covariance matrix $\P _{\ti }$ and its Riemannian mean class $\P _{\Rm }^{(\ci )}$ is shown as connection line. The black star represents the Riemannian mean of all trials. Subject with lowest BCI performance, (\ref {fig:tan_plan_s16_a}) before and (\ref {fig:tan_plan_s16_b}) after Riemannian potato filtering. Subject with highest BCI performance, (\ref {fig:tan_plan_s17_a}) before and (\ref {fig:tan_plan_s17_b}) after Riemannian potato filtering}{figure.5.4}{}}
\newlabel{fig:covmat12}{{5.5(a)}{105}{Subfigure 5 5.5(a)}{subfigure.5.5.1}{}}
\newlabel{sub@fig:covmat12}{{(a)}{105}{Subfigure 5 5.5(a)\relax }{subfigure.5.5.1}{}}
\newlabel{fig:covmat11}{{5.5(b)}{105}{Subfigure 5 5.5(b)}{subfigure.5.5.2}{}}
\newlabel{sub@fig:covmat11}{{(b)}{105}{Subfigure 5 5.5(b)\relax }{subfigure.5.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Representation of covariance matrices: each image is the covariance matrix mean $\ensuremath  {\mathaccentV {bar}016{\ensuremath  {\Sigma }}}^{(\ensuremath  {k})}$ of the class $\ensuremath  {k}$, for one session of the recording. The diagonal blocks show the covariance in different frequency bands, i.e. 13 Hz in the upper-left block, 21 Hz in the middle, and 17 Hz in the bottom-right. Subjects with highest (a) and lowest (b) BCI performance. }}{105}{figure.5.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{105}{figure.5.5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{105}{figure.5.5}}
\newlabel{fig:covmat}{{5.5}{105}{Representation of covariance matrices: each image is the covariance matrix mean $\Pm ^{(\ci )}$ of the class $\ci $, for one session of the recording. The diagonal blocks show the covariance in different frequency bands, i.e. 13 Hz in the upper-left block, 21 Hz in the middle, and 17 Hz in the bottom-right. Subjects with highest (a) and lowest (b) BCI performance}{figure.5.5}{}}
\newlabel{fig:swel}{{5.6(a)}{106}{Subfigure 5 5.6(a)}{subfigure.5.6.1}{}}
\newlabel{sub@fig:swel}{{(a)}{106}{Subfigure 5 5.6(a)\relax }{subfigure.5.6.1}{}}
\newlabel{fig:alphacross}{{5.6(b)}{106}{Subfigure 5 5.6(b)}{subfigure.5.6.2}{}}
\newlabel{sub@fig:alphacross}{{(b)}{106}{Subfigure 5 5.6(b)\relax }{subfigure.5.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces (a): Swelling effect of Arithmetic mean shown through log-determinant values. Training trials are taken from the 13 Hz class of the subject with the highest BCI performance. Log-determinant values are given for each trial covariance (points), and for means of Table\nobreakspace  {}\ref  {tab:dist} (horizontal lines). (b): Classification accuracy and CPU time, obtained with $\alpha $-divergence for $-1\leqslant \alpha \leqslant 1$.}}{106}{figure.5.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{106}{figure.5.6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{106}{figure.5.6}}
\newlabel{fig:swel_alpha}{{5.6}{106}{(a): Swelling effect of Arithmetic mean shown through log-determinant values. Training trials are taken from the 13 Hz class of the subject with the highest BCI performance. Log-determinant values are given for each trial covariance (points), and for means of Table~\ref {tab:dist} (horizontal lines). (b): Classification accuracy and CPU time, obtained with $\alpha $-divergence for $-1\leqslant \alpha \leqslant 1$}{figure.5.6}{}}
\citation{lin_frequency_2006}
\citation{nakanishi_high-speed_2014}
\citation{kimura_ssvep-based_2013,nakanishi_high-speed_2014}
\citation{vialatte_steady-state_2010,bakardjian_optimization_2010}
\citation{lin_frequency_2006}
\citation{nakanishi_high-speed_2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}Classification Results and Analysis}{107}{subsection.5.5.4}}
\newlabel{sec:ssvep_response_delay}{{5.5.4}{107}{Classification Results and Analysis}{subsection.5.5.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Offline Analysis}{107}{section*.27}}
\newlabel{sec:offline_analysis}{{5.5.4}{107}{Offline Analysis}{section*.27}{}}
\newlabel{fig:sync_delay_best}{{5.7(a)}{108}{Subfigure 5 5.7(a)}{subfigure.5.7.1}{}}
\newlabel{sub@fig:sync_delay_best}{{(a)}{108}{Subfigure 5 5.7(a)\relax }{subfigure.5.7.1}{}}
\newlabel{fig:sync_delay_worst}{{5.7(b)}{108}{Subfigure 5 5.7(b)}{subfigure.5.7.2}{}}
\newlabel{sub@fig:sync_delay_worst}{{(b)}{108}{Subfigure 5 5.7(b)\relax }{subfigure.5.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Signal amplitude at each stimulus frequency, showing synchronisation of EEG with respect to time (seconds). The raw signal of the trial measured on Oz is band filtered using a Butterworth of order 8 at each stimulus frequency and the resulting signals are shown in blue (dark grey), green (grey), and red (light grey) for the same signal filtered respectively at 13, 17, and 21 Hz. The cue onset $\ensuremath  {\tau _0}$ at time $0$ on the x-axis is shown with a vertical discontinued line. 4 trials are shown, one for each class. Signals are from the subjects with the highest (\ref  {fig:sync_delay_best}) and with the lowest BCI performance (\ref  {fig:sync_delay_worst}).}}{108}{figure.5.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{108}{figure.5.7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{108}{figure.5.7}}
\newlabel{fig:sync_delay}{{5.7}{108}{Signal amplitude at each stimulus frequency, showing synchronisation of EEG with respect to time (seconds). The raw signal of the trial measured on Oz is band filtered using a Butterworth of order 8 at each stimulus frequency and the resulting signals are shown in blue (dark grey), green (grey), and red (light grey) for the same signal filtered respectively at 13, 17, and 21 Hz. The cue onset $\cue $ at time $0$ on the x-axis is shown with a vertical discontinued line. 4 trials are shown, one for each class. Signals are from the subjects with the highest (\ref {fig:sync_delay_best}) and with the lowest BCI performance (\ref {fig:sync_delay_worst})}{figure.5.7}{}}
\citation{lin_frequency_2006}
\citation{nakanishi_high-speed_2014}
\citation{nakanishi_high-speed_2014}
\citation{lin_frequency_2006}
\citation{nakanishi_high-speed_2014}
\citation{lin_frequency_2006}
\citation{nakanishi_high-speed_2014}
\@writefile{toc}{\contentsline {subsubsection}{Online Analysis without Resting Class}{109}{section*.28}}
\citation{lin_frequency_2006}
\citation{nakanishi_high-speed_2014}
\@writefile{toc}{\contentsline {subsubsection}{Online Analysis with Resting Class}{111}{section*.29}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Conclusion}{112}{section.5.6}}
\newlabel{sec:riem-conclusion}{{5.6}{112}{Conclusion}{section.5.6}{}}
\newlabel{RF1}{114}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Subject classification accuracy (acc(\%)) and average CPU time (time(s)) elapsed for the classification of a single trial. Classification is performed with MDM using either Euclidean or Riemannian means (see Table\nobreakspace  {}\ref  {tab:dist}).}}{114}{table.5.2}}
\newlabel{tab:res}{{5.2}{114}{Subject classification accuracy (acc(\%)) and average CPU time (time(s)) elapsed for the classification of a single trial. Classification is performed with MDM using either Euclidean or Riemannian means (see Table~\ref {tab:dist})}{table.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Offline performance in terms of accuracy and ITR. Five methods are compared: (1) CCA approach introduced by \citep  {lin_frequency_2006}, (2) CCA approach introduced by \citep  {nakanishi_high-speed_2014}, (3) MDRM described in Section \ref  {subsec:mdm} (Algorithm \ref  {alg:mdm}), (4) MDRM where processed epochs are taken 2 seconds from the beginning of the trial, and (5) MDRM-Potato, where outliers are removed using the Riemannian potato approach described in Section\nobreakspace  {}\ref  {sec:potato}.}}{115}{table.5.3}}
\newlabel{tab:res-offline}{{5.3}{115}{Offline performance in terms of accuracy and ITR. Five methods are compared: (1) CCA approach introduced by \citep {lin_frequency_2006}, (2) CCA approach introduced by \citep {nakanishi_high-speed_2014}, (3) MDRM described in Section \ref {subsec:mdm} (Algorithm \ref {alg:mdm}), (4) MDRM where processed epochs are taken 2 seconds from the beginning of the trial, and (5) \mdrmpotato , where outliers are removed using the Riemannian potato approach described in Section~\ref {sec:potato}}{table.5.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Classification performances (accuracy in \%, delay before valid and confident classification in seconds, and ITR in bits/min) achieved using the online algorithm. The first column indicates the subjects. The following three columns show the results obtained without the curve direction criterion (Algorithm \ref  {alg:online} up to \ref  {op3:test_rho}): by stopping at step \ref  {op3:test_rho}, $\ensuremath  {\mathaccentV {bar}016{\ensuremath  {k}}}$ is taken to be the valid class. The next three columns contain the results of the complete online algorithm. The last three columns report the results obtained when outliers are removed in the training phase using the Riemannian potato technique described in Section \ref  {sec:potato}.}}{115}{table.5.4}}
\newlabel{tab:res-online}{{5.4}{115}{Classification performances (accuracy in \%, delay before valid and confident classification in seconds, and ITR in bits/min) achieved using the online algorithm. The first column indicates the subjects. The following three columns show the results obtained without the curve direction criterion (Algorithm \ref {alg:online} up to \ref {op3:test_rho}): by stopping at step \ref {op3:test_rho}, $\cloutmp $ is taken to be the valid class. The next three columns contain the results of the complete online algorithm. The last three columns report the results obtained when outliers are removed in the training phase using the Riemannian potato technique described in Section \ref {sec:potato}}{table.5.4}{}}
\newlabel{fig:classErrorEpochs}{{5.8(a)}{116}{Subfigure 5 5.8(a)}{subfigure.5.8.1}{}}
\newlabel{sub@fig:classErrorEpochs}{{(a)}{116}{Subfigure 5 5.8(a)\relax }{subfigure.5.8.1}{}}
\newlabel{fig:classProbEpochs}{{5.8(b)}{116}{Subfigure 5 5.8(b)}{subfigure.5.8.2}{}}
\newlabel{sub@fig:classProbEpochs}{{(b)}{116}{Subfigure 5 5.8(b)\relax }{subfigure.5.8.2}{}}
\newlabel{fig:errorProbTresh}{{5.8(c)}{116}{Subfigure 5 5.8(c)}{subfigure.5.8.3}{}}
\newlabel{sub@fig:errorProbTresh}{{(c)}{116}{Subfigure 5 5.8(c)\relax }{subfigure.5.8.3}{}}
\newlabel{fig:accaracy_tlen}{{5.8(d)}{116}{Subfigure 5 5.8(d)}{subfigure.5.8.4}{}}
\newlabel{sub@fig:accaracy_tlen}{{(d)}{116}{Subfigure 5 5.8(d)\relax }{subfigure.5.8.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Evaluation of the online algorithm parameters. \ref  {fig:classErrorEpochs} shows the decrease of the average classification error over all subjects during the successive epochs after the beginning of the trial. \ref  {fig:classProbEpochs} is an example taken from the subject with the best performance showing how the probability of the actual class varies with epoch position from beginning of trial. The groundtruth class probability is represented with a thick-and-star line, while other classes probability lines are thin-and-diamond. \ref  {fig:errorProbTresh} shows the variation of the average classification error for different probability threshold ($0 \leqslant \ensuremath  {\vartheta }< 1$) and its influence on the classifier output (Algorithm \ref  {alg:online} step \ref  {op3:test_rho}). \ref  {fig:accaracy_tlen} shows how the average online performance varies with respect to the epoch size ($\ensuremath  {w}$). It shows both the classification accuracy (left y-axis) and the ITR (right y-axis). In \ref  {fig:classErrorEpochs}, \ref  {fig:errorProbTresh}, and \ref  {fig:accaracy_tlen}, the bars represent the error of the mean i.e. standard deviation divided by the square root of $n-1$, $n$ = number of samples.}}{116}{figure.5.8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{116}{figure.5.8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{116}{figure.5.8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{116}{figure.5.8}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{116}{figure.5.8}}
\newlabel{fig:probErrorEpochs}{{5.8}{116}{Evaluation of the online algorithm parameters. \ref {fig:classErrorEpochs} shows the decrease of the average classification error over all subjects during the successive epochs after the beginning of the trial. \ref {fig:classProbEpochs} is an example taken from the subject with the best performance showing how the probability of the actual class varies with epoch position from beginning of trial. The groundtruth class probability is represented with a thick-and-star line, while other classes probability lines are thin-and-diamond. \ref {fig:errorProbTresh} shows the variation of the average classification error for different probability threshold ($0 \leqslant \pthres < 1$) and its influence on the classifier output (Algorithm \ref {alg:online} step \ref {op3:test_rho}). \ref {fig:accaracy_tlen} shows how the average online performance varies with respect to the epoch size ($\ws $). It shows both the classification accuracy (left y-axis) and the ITR (right y-axis). In \ref {fig:classErrorEpochs}, \ref {fig:errorProbTresh}, and \ref {fig:accaracy_tlen}, the bars represent the error of the mean i.e. standard deviation divided by the square root of $n-1$, $n$ = number of samples}{figure.5.8}{}}
\newlabel{fig:class_path1_s17}{{5.9(a)}{117}{Subfigure 5 5.9(a)}{subfigure.5.9.1}{}}
\newlabel{sub@fig:class_path1_s17}{{(a)}{117}{Subfigure 5 5.9(a)\relax }{subfigure.5.9.1}{}}
\newlabel{fig:class_path2_s17}{{5.9(b)}{117}{Subfigure 5 5.9(b)}{subfigure.5.9.2}{}}
\newlabel{sub@fig:class_path2_s17}{{(b)}{117}{Subfigure 5 5.9(b)\relax }{subfigure.5.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces The covariance matrices trajectory during a 4-class SSVEP online recording. The circles represent class centres. The triangles mark the beginning of the experiment of a new trial whose class is indicated by the triangle's colour. \ref  {fig:class_path1_s17} shows the first 7 trials. The first 3 trials are from the resting class, the remaining are respectively class 13 Hz, 17 Hz, and 21 Hz. \ref  {fig:class_path2_s17} shows the entire recording. Data are taken from the subject with the highest BCI performance.}}{117}{figure.5.9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{117}{figure.5.9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{117}{figure.5.9}}
\newlabel{fig:class_path_s17}{{5.9}{117}{The covariance matrices trajectory during a 4-class SSVEP online recording. The circles represent class centres. The triangles mark the beginning of the experiment of a new trial whose class is indicated by the triangle's colour. \ref {fig:class_path1_s17} shows the first 7 trials. The first 3 trials are from the resting class, the remaining are respectively class 13 Hz, 17 Hz, and 21 Hz. \ref {fig:class_path2_s17} shows the entire recording. Data are taken from the subject with the highest BCI performance}{figure.5.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces This table summarises the performance achieved with the online algorithm with resting class identification, as in Table\nobreakspace  {}\ref  {tab:res-online}. }}{117}{table.5.5}}
\newlabel{tab:res-online-resting}{{5.5}{117}{This table summarises the performance achieved with the online algorithm with resting class identification, as in Table~\ref {tab:res-online}}{table.5.5}{}}
\newlabel{fig:confusion-matrix}{{5.10(a)}{118}{Subfigure 5 5.10(a)}{subfigure.5.10.1}{}}
\newlabel{sub@fig:confusion-matrix}{{(a)}{118}{Subfigure 5 5.10(a)\relax }{subfigure.5.10.1}{}}
\newlabel{fig:roc-curve}{{5.10(b)}{118}{Subfigure 5 5.10(b)}{subfigure.5.10.2}{}}
\newlabel{sub@fig:roc-curve}{{(b)}{118}{Subfigure 5 5.10(b)\relax }{subfigure.5.10.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces (a) Confusion matrix for $K=4$ classes with Online-Potato. (b): ROC curve indicating the influence of the $\ensuremath  {\vartheta }$ parameter. }}{118}{figure.5.10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{118}{figure.5.10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{118}{figure.5.10}}
\newlabel{fig:cm-roc}{{5.10}{118}{(a) Confusion matrix for $K=4$ classes with \onlinepotato . (b): ROC curve indicating the influence of the $\pthres $ parameter}{figure.5.10}{}}
\@setckpt{T5}{
\setcounter{page}{119}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{5}
\setcounter{Item}{13}
\setcounter{Hfootnote}{2}
\setcounter{bookmark@seq@number}{64}
\setcounter{float@type}{8}
\setcounter{parentequation}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{algorithm}{3}
\setcounter{ALG@line}{14}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{lips@count}{0}
\setcounter{r@tfl@t}{1}
\setcounter{AM@survey}{0}
\setcounter{NAT@ctr}{0}
\setcounter{thm}{0}
\setcounter{defn}{0}
\setcounter{rem}{0}
\setcounter{section@level}{1}
}
